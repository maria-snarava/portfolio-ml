{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9abac94c",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c40e2b",
   "metadata": {},
   "source": [
    "In this file, I prepare data from the [Kaggle dataset](https://www.kaggle.com/datasets/omermetinn/tweets-about-the-top-companies-from-2015-to-2020/data) for use on the Dashboard. The original dataset is too big(4M tweets and more than 700MB) for learning purposes, so I am going to use only tweets from 2019. The original dataset is not committed to GitHub; you can additionally load it from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "618b1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "tweet_file = Path(\"../data/Tweet.csv\")\n",
    "company_tweet_file = Path(\"../data/Company_Tweet.csv\")\n",
    "company_file = Path(\"../data/Company.csv\")\n",
    "output_file  = Path(\"../data/prepared_data.csv\")\n",
    "\n",
    "if os.path.isfile(tweet_file) and os.path.isfile(company_tweet_file):\n",
    "    # Load the CSV file\n",
    "    tweets = pd.read_csv(tweet_file)\n",
    "    company_tweet = pd.read_csv(company_tweet_file)\n",
    "    # Merge files\n",
    "    tweets = tweets.merge(company_tweet, how='left', on='tweet_id')\n",
    "    # Format dates\n",
    "    tweets['date'] = pd.to_datetime(tweets['post_date'], unit='s').dt.date\n",
    "    tweets.date = pd.to_datetime( tweets.date,errors='coerce')\n",
    "    tweets['time'] = pd.to_datetime(tweets['post_date'], unit='s').dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3f758",
   "metadata": {},
   "source": [
    "I am going to use only 2019 year's tweets, because this dataset too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2356b45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336445\n",
      "905311\n"
     ]
    }
   ],
   "source": [
    "tweets_2019 = tweets[tweets['date'].dt.year == 2019]\n",
    "print(len(tweets))\n",
    "print(len(tweets_2019))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707bca6",
   "metadata": {},
   "source": [
    "We can see than selected dataset in 4 times smaller than the original one.\n",
    "\n",
    "Add company name's to dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8814f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(company_file):\n",
    "    company = pd.read_csv(company_file)\n",
    "    tweets_2019 = tweets_2019.merge(company, how='left', on='ticker_symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80819945",
   "metadata": {},
   "source": [
    "Drop columns, which value doesn't necessary for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91379dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1079890068867817473</td>\n",
       "      <td>evdefender</td>\n",
       "      <td>1546300830</td>\n",
       "      <td>!!  8 Hours Left !!The picture you see here is...</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>82</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:30</td>\n",
       "      <td>Tesla Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1079890105282842629</td>\n",
       "      <td>ExactOptionPick</td>\n",
       "      <td>1546300839</td>\n",
       "      <td>Don't miss our next FREE OPTION TRADE.  Sign u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:39</td>\n",
       "      <td>Google Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1079890627335213057</td>\n",
       "      <td>traderDanielle</td>\n",
       "      <td>1546300963</td>\n",
       "      <td>Rinse and repeat - looking for entries in $XLC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:02:43</td>\n",
       "      <td>Google Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1079890718326431745</td>\n",
       "      <td>O__rust</td>\n",
       "      <td>1546300985</td>\n",
       "      <td>$3750 would be the minimum discount in any cas...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:03:05</td>\n",
       "      <td>Tesla Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1079890782742503424</td>\n",
       "      <td>GunGermSteel</td>\n",
       "      <td>1546301000</td>\n",
       "      <td>There are FUDking analysts like those from gol...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:03:20</td>\n",
       "      <td>Tesla Inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           writer   post_date  \\\n",
       "0  1079890068867817473       evdefender  1546300830   \n",
       "1  1079890105282842629  ExactOptionPick  1546300839   \n",
       "2  1079890627335213057   traderDanielle  1546300963   \n",
       "3  1079890718326431745          O__rust  1546300985   \n",
       "4  1079890782742503424     GunGermSteel  1546301000   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  !!  8 Hours Left !!The picture you see here is...            6   \n",
       "1  Don't miss our next FREE OPTION TRADE.  Sign u...            0   \n",
       "2  Rinse and repeat - looking for entries in $XLC...            0   \n",
       "3  $3750 would be the minimum discount in any cas...            0   \n",
       "4  There are FUDking analysts like those from gol...            0   \n",
       "\n",
       "   retweet_num  like_num ticker_symbol       date      time company_name  \n",
       "0           16        82          TSLA 2019-01-01  00:00:30    Tesla Inc  \n",
       "1            0         0         GOOGL 2019-01-01  00:00:39   Google Inc  \n",
       "2            0         3         GOOGL 2019-01-01  00:02:43   Google Inc  \n",
       "3            0         0          TSLA 2019-01-01  00:03:05    Tesla Inc  \n",
       "4            0         1          TSLA 2019-01-01  00:03:20    Tesla Inc  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80fc3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2019 = tweets_2019.drop('tweet_id', axis=1)\n",
    "tweets_2019 = tweets_2019.drop('writer', axis=1)\n",
    "tweets_2019 = tweets_2019.drop('post_date', axis=1)\n",
    "tweets_2019 = tweets_2019.drop('ticker_symbol', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "741ce0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body',\n",
       " 'comment_num',\n",
       " 'retweet_num',\n",
       " 'like_num',\n",
       " 'date',\n",
       " 'time',\n",
       " 'company_name']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tweets_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c27160e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>905311.000000</td>\n",
       "      <td>905311.000000</td>\n",
       "      <td>905311.000000</td>\n",
       "      <td>905311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.604147</td>\n",
       "      <td>0.901069</td>\n",
       "      <td>4.928085</td>\n",
       "      <td>2019-06-20 00:12:43.112786432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019-06-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2019-09-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>567.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>2019-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.207685</td>\n",
       "      <td>6.756438</td>\n",
       "      <td>24.012596</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comment_num    retweet_num       like_num  \\\n",
       "count  905311.000000  905311.000000  905311.000000   \n",
       "mean        0.604147       0.901069       4.928085   \n",
       "min         0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       1.000000   \n",
       "75%         0.000000       0.000000       2.000000   \n",
       "max       567.000000     989.000000     995.000000   \n",
       "std         3.207685       6.756438      24.012596   \n",
       "\n",
       "                                date  \n",
       "count                         905311  \n",
       "mean   2019-06-20 00:12:43.112786432  \n",
       "min              2019-01-01 00:00:00  \n",
       "25%              2019-03-21 00:00:00  \n",
       "50%              2019-06-05 00:00:00  \n",
       "75%              2019-09-20 00:00:00  \n",
       "max              2019-12-31 00:00:00  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_2019.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e1483",
   "metadata": {},
   "source": [
    "### Identifying Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d99b9d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body            0.0\n",
       "comment_num     0.0\n",
       "retweet_num     0.0\n",
       "like_num        0.0\n",
       "date            0.0\n",
       "time            0.0\n",
       "company_name    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((tweets_2019.isnull().sum()*100 / tweets_2019.shape[0]),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4776709",
   "metadata": {},
   "source": [
    "There are no missed values. \n",
    "\n",
    "### Prepare tweets body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4874123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!  8 Hours Left !!The picture you see here is...</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>82</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:30</td>\n",
       "      <td>Tesla Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don't miss our next FREE OPTION TRADE.  Sign u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:39</td>\n",
       "      <td>Google Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rinse and repeat - looking for entries in XLC,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:02:43</td>\n",
       "      <td>Google Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3750 would be the minimum discount in any case...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:03:05</td>\n",
       "      <td>Tesla Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are FUDking analysts like those from gol...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:03:20</td>\n",
       "      <td>Tesla Inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  comment_num  \\\n",
       "0  !!  8 Hours Left !!The picture you see here is...            6   \n",
       "1  Don't miss our next FREE OPTION TRADE.  Sign u...            0   \n",
       "2  Rinse and repeat - looking for entries in XLC,...            0   \n",
       "3  3750 would be the minimum discount in any case...            0   \n",
       "4  There are FUDking analysts like those from gol...            0   \n",
       "\n",
       "   retweet_num  like_num       date      time company_name  \n",
       "0           16        82 2019-01-01  00:00:30    Tesla Inc  \n",
       "1            0         0 2019-01-01  00:00:39   Google Inc  \n",
       "2            0         3 2019-01-01  00:02:43   Google Inc  \n",
       "3            0         0 2019-01-01  00:03:05    Tesla Inc  \n",
       "4            0         1 2019-01-01  00:03:20    Tesla Inc  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "replacement_text=\"[URL REMOVED]\"\n",
    "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "\n",
    "tweets_2019['body'] = tweets_2019['body'].str.replace('$', '')\n",
    "tweets_2019['body'] = tweets_2019['body'].apply(lambda x: url_pattern.sub(replacement_text, x))\n",
    "\n",
    "tweets_2019.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe527ecd",
   "metadata": {},
   "source": [
    "### Add Engagement mentric for tweet\n",
    "\n",
    "Combine fields 'comment_num', 'retweet_num' and 'like_num' to one field with diffirent wieghts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88475a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2019 = pd.read_csv(output_file)\n",
    "tweets_2019['engagement'] = tweets_2019['comment_num'] * 3 + tweets_2019['retweet_num'] * 2 + tweets_2019['like_num']\n",
    "tweets_2019 = tweets_2019.drop('comment_num', axis=1)\n",
    "tweets_2019 = tweets_2019.drop('retweet_num', axis=1)\n",
    "tweets_2019 = tweets_2019.drop('like_num', axis=1)\n",
    "\n",
    "tweets_2019.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4a6e9",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f35942f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/work/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d58de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple misses earnings, analyst suggest downgrade , sell now \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.213, 'neu': 0.787, 'pos': 0.0, 'compound': -0.2263}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(tweets):\n",
    "    # applt the SentimentIntensityAnalyzer\n",
    "    tweets.loc[:,('score')]=tweets.loc[:,'body'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "    # create label\n",
    "    #bins= pd.interval_range(start=-1, freq=3, end=1)\n",
    "    tweets.loc[:,('sentiment')]=pd.cut(np.array(tweets.loc[:,'score']),bins=[-1, -0.66, 0.32, 1],right=True ,labels=('negative', 'neutral', 'positive'))\n",
    "    \n",
    "    df=tweets.loc[:,[\"date\",\"score\",\"sentiment\",\"body\"]]\n",
    "    return df\n",
    "\n",
    "print('apple misses earnings, analyst suggest downgrade , sell now ')\n",
    "sia.polarity_scores('apple misses earnings, analyst suggest downgrade , sell now ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9de31ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple misses earnings, analyst suggest downgrade , sell now \n",
      "{'neg': 0.535, 'neu': 0.465, 'pos': 0.0, 'compound': -0.7845}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>-0.5216</td>\n",
       "      <td>neutral</td>\n",
       "      <td>!!  8 Hours Left !!The picture you see here is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.9493</td>\n",
       "      <td>positive</td>\n",
       "      <td>Don't miss our next FREE OPTION TRADE.  Sign u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Rinse and repeat - looking for entries in XLC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3750 would be the minimum discount in any case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>positive</td>\n",
       "      <td>There are FUDking analysts like those from gol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   score sentiment  \\\n",
       "0 2019-01-01 -0.5216   neutral   \n",
       "1 2019-01-01  0.9493  positive   \n",
       "2 2019-01-01  0.6428  positive   \n",
       "3 2019-01-01  0.0875   neutral   \n",
       "4 2019-01-01  0.3612  positive   \n",
       "\n",
       "                                                body  \n",
       "0  !!  8 Hours Left !!The picture you see here is...  \n",
       "1  Don't miss our next FREE OPTION TRADE.  Sign u...  \n",
       "2  Rinse and repeat - looking for entries in XLC,...  \n",
       "3  3750 would be the minimum discount in any case...  \n",
       "4  There are FUDking analysts like those from gol...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# augment vocab\n",
    "\n",
    "positive_words='high profit Growth Potential Opportunity Bullish Strong Valuable Success Promising Profitable Win Winner Outstanding Record Earnings Breakthrough buy bull long support undervalued underpriced cheap upward rising trend moon rocket hold breakout call beat support buying holding free ready'\n",
    "negative_words='resistance squeeze cover seller Risk Loss Decline Bearish Weak Declining Uncertain Troubling Downturn Struggle Unstable Volatile Slump Disaster Plunge sell bear bubble bearish short overvalued overbought overpriced expensive downward falling sold sell low put miss'\n",
    "\n",
    "dictOfpos = { i : 4 for i in positive_words.split(\" \") }\n",
    "dictOfneg = { i : -4 for i in negative_words.split(\" \")  }\n",
    "Financial_Lexicon = {**dictOfpos, **dictOfneg}\n",
    "\n",
    "sia.lexicon.update(Financial_Lexicon)\n",
    "\n",
    "print('apple misses earnings, analyst suggest downgrade , sell now ')\n",
    "print(sia.polarity_scores('apple misses earnings, analyst suggest downgrade , sell now '))\n",
    "\n",
    "tw=get_sentiment(tweets_2019) # get tweets\n",
    "tw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285ff2d",
   "metadata": {},
   "source": [
    "### Save data for dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a99c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2019.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "700600b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2019 = pd.read_csv(output_file)\n",
    "tweets_2019.iloc[:len(tweets_2019)//2,:].to_csv(f'{output_file}_1', index=False)\n",
    "tweets_2019.iloc[len(tweets_2019)//2:,:].to_csv(f'{output_file}_2', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c43500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
